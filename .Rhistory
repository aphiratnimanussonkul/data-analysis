} else {
for (j in 1:index) {
print(paste("j  = ", temp_vect_nor[j]))
if (temp_vect_nor[j] == i) {
count[j] <- as.numeric(count[j]) + 1
isRepeate = T
}
}
if (!isRepeate) {
index <- index + 1
temp_vect_nor[index] <- i
count[index] <- 1
}
}
isRepeate = F
}
print(vector_normal_dis)
vector_normal_dis <- c(sample(1:20, 50, replace = T))
vector_normal_dis <- c(sample(1:20, 50, replace = T))
count = list()
temp_vect_nor = list()
index = 0
isRepeate = F
for (i in vector_normal_dis) {
print(i)
if (index == 0) {
index <- index + 1
print("index = 1")
temp_vect_nor[index] <- i
count[index] <- 1
} else {
for (j in 1:index) {
print(paste("j  = ", temp_vect_nor[j]))
if (temp_vect_nor[j] == i) {
count[j] <- as.numeric(count[j]) + 1
isRepeate = T
}
}
if (!isRepeate) {
index <- index + 1
temp_vect_nor[index] <- i
count[index] <- 1
}
}
isRepeate = F
}
print(vector_normal_dis)
View(temp_vect_nor)
View(temp_vect_nor)
View(count)
View(count)
summary_repeate <- cbin(unlist(temp_vect_nor), unlist(count))
summary_repeate <- cbind(unlist(temp_vect_nor), unlist(count))
View(summary_repeate)
View(summary_repeate)
vector_normal_dis <- c(sample(1:25, 50, replace = T))
count = list()
temp_vect_nor = list()
index = 0
isRepeate = F
for (i in vector_normal_dis) {
print(i)
if (index == 0) {
index <- index + 1
print("index = 1")
temp_vect_nor[index] <- i
count[index] <- 1
} else {
for (j in 1:index) {
print(paste("j  = ", temp_vect_nor[j]))
if (temp_vect_nor[j] == i) {
count[j] <- as.numeric(count[j]) + 1
isRepeate = T
}
}
if (!isRepeate) {
index <- index + 1
temp_vect_nor[index] <- i
count[index] <- 1
}
}
isRepeate = F
}
summary_repeate <- cbind(unlist(temp_vect_nor), unlist(count))
print(vector_normal_dis)
View(summary_repeate)
View(summary_repeate)
count_re <- table(temp_vect_nor)
View(count_re)
count_re <- table(vector_normal_dis)
View(count_re)
View(count)
View(count)
# à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸£à¸µà¸”à¹‰à¸§à¸¢ package rpart
# à¹€à¸£à¸²à¸ªà¸²à¸¡à¸²à¸£à¸–à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸£à¸µà¸”à¹‰à¸§à¸¢à¸Ÿà¸±à¸‡à¸à¸Šà¸±à¸™ à¹Œ rpart( ) à¸‹à¸¶à¹ˆà¸‡à¸­à¸¢à¸¹à¹ƒà¸™ à¹ˆ package rpart à¹à¸¥à¸°à¸—à¸”à¸ªà¸­à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Test à¸”à¹‰à¸§à¸¢
# à¸Ÿà¸±à¸‡à¸à¸Šà¸±à¸™ à¹Œ predict( ) à¹ƒà¸™à¸—à¸µà¹ˆà¸™à¸µà¹‰à¸ˆà¸°à¹ƒà¸Šà¹‰à¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¸± bodyfat
titanic_train <- read.csv("C://cygwin64//home//AphiratNimanussonkul//data-analysis/titanic_train.csv")
titanic_test <- read.csv("C://cygwin64//home//AphiratNimanussonkul//data-analysis/titanic_test.csv")
titanic_train$Survived <- as.factor(titanic_train$Survived)
titanic_test$Survived <- as.factor(titanic_test$Survived)
library(rpart)
library(rpart.plot)
#create model
tree_fit <- rpart(Survived ~ ., data = titanic_train)
#test model
p <- predict(tree_fit, newdata = titanic_test, type = "class")
mean(p == titanic_test$Survived)
rpart.plot(tree_fit)
table(p, titinic_test$Survived)
table(p, titanic_test$Survived)
Sys.setlocale(locale = "Thai")
tree_fit <- prune(tree_fit, cp = 0.444444)
#test model
#type = class is à¸•à¹‰à¸­à¸‡à¸£à¸°à¸šà¸¸à¸à¸²à¸£ predict class => classification
p <- predict(tree_fit, newdata = titanic_test, type = "class")
#à¸«à¸²à¸„à¹ˆà¸²à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸‚à¸­à¸‡ Model à¸ˆà¸°à¹„à¸”à¹‰à¸„à¹ˆà¸² 0.901 * 100 %
mean(p == titanic_test$Survived)
table(p, titanic_test$Survived)
library(mboost)
library(mboost)
data("bodyfat", package = "mboost")
# à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸£à¸µà¸”à¹‰à¸§à¸¢ package rpart
# à¹€à¸£à¸²à¸ªà¸²à¸¡à¸²à¸£à¸–à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸£à¸µà¸”à¹‰à¸§à¸¢à¸Ÿà¸±à¸‡à¸à¸Šà¸±à¸™ à¹Œ rpart( ) à¸‹à¸¶à¹ˆà¸‡à¸­à¸¢à¸¹à¹ƒà¸™ à¹ˆ package rpart à¹à¸¥à¸°à¸—à¸”à¸ªà¸­à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Test à¸”à¹‰à¸§à¸¢
# à¸Ÿà¸±à¸‡à¸à¸Šà¸±à¸™ à¹Œ predict( ) à¹ƒà¸™à¸—à¸µà¹ˆà¸™à¸µà¹‰à¸ˆà¸°à¹ƒà¸Šà¹‰à¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¸± bodyfat
titanic_train <- read.csv("C://cygwin64//home//AphiratNimanussonkul//data-analysis/titanic_train.csv")
titanic_test <- read.csv("C://cygwin64//home//AphiratNimanussonkul//data-analysis/titanic_test.csv")
#as.factor à¹ƒà¸Šà¹‰à¹à¸›à¸¥à¸‡à¸„à¹ˆà¸² int à¸ˆà¸²à¸ à¸„à¸­à¸¥à¸±à¸¡ survied à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹à¸›à¸£ factor tree à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ à¸•à¸±à¸§à¹à¸›à¸£à¹à¸šà¸š factor à¹€à¸—à¹ˆà¸²à¸™à¹‰à¸™
titanic_train$Survived <- as.factor(titanic_train$Survived)
titanic_test$Survived <- as.factor(titanic_test$Survived)
# à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸£à¸µà¸”à¹‰à¸§à¸¢ package rpart
# à¹€à¸£à¸²à¸ªà¸²à¸¡à¸²à¸£à¸–à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸£à¸µà¸”à¹‰à¸§à¸¢à¸Ÿà¸±à¸‡à¸à¸Šà¸±à¸™ à¹Œ rpart( ) à¸‹à¸¶à¹ˆà¸‡à¸­à¸¢à¸¹à¹ƒà¸™ à¹ˆ package rpart à¹à¸¥à¸°à¸—à¸”à¸ªà¸­à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Test à¸”à¹‰à¸§à¸¢
# à¸Ÿà¸±à¸‡à¸à¸Šà¸±à¸™ à¹Œ predict( ) à¹ƒà¸™à¸—à¸µà¹ˆà¸™à¸µà¹‰à¸ˆà¸°à¹ƒà¸Šà¹‰à¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¸± bodyfat
titanic_train <- read.csv("C://cygwin64//home//AphiratNimanussonkul//data-analysis/titanic_train.csv")
titanic_test <- read.csv("C://cygwin64//home//AphiratNimanussonkul//data-analysis/titanic_test.csv")
#as.factor à¹ƒà¸Šà¹‰à¹à¸›à¸¥à¸‡à¸„à¹ˆà¸² int à¸ˆà¸²à¸ à¸„à¸­à¸¥à¸±à¸¡ survied à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹à¸›à¸£ factor tree à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ à¸•à¸±à¸§à¹à¸›à¸£à¹à¸šà¸š factor à¹€à¸—à¹ˆà¸²à¸™à¹‰à¸™
titanic_train$Survived <- as.factor(titanic_train$Survived)
titanic_test$Survived <- as.factor(titanic_test$Survived)
rf <- randomForest(Survived ~ ., data = titanic_train, ntree = 100)
library(randomForest)
# à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥ Random Forest (à¸à¸¥à¸¸à¹ˆà¸¡à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸£à¸µ)
# à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¸Ÿà¸±à¸‡à¸à¸Šà¸±à¸™ à¹Œ randomForest( ) à¸ˆà¸²à¸ package randomForest
# à¸‚à¹‰à¸­ à¸”à¹‰à¸­à¸¢à¸‚à¸­à¸‡à¸Ÿà¸±à¸‡à¸à¸Šà¸±à¸™à¸™à¸µ à¹Œ à¹‰à¸„à¸·à¸­
# 1.à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰à¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¡à¸µ à¸± missing value (à¸ˆà¸°à¸•à¹‰à¸­à¸‡à¸ˆà¸±à¸”à¸à¸²à¸£à¸à¸šà¸± missing valueà¸à¹ˆà¸­à¸™à¸— à¸²à¸‡à¸²à¸™)
# 2. à¹à¸•à¹ˆà¸¥à¸°à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™à¸Šà¸™à¸´à¸” categorical à¸ˆà¸°à¸¡à¸µà¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸•à¹ˆà¸²à¸‡à¸à¸™à¹„à¸¡ à¸± à¹ˆà¹€à¸à¸´à¸™ 32 à¸„à¹ˆà¸² (à¸­à¸²à¸ˆà¸ˆà¸°à¹ƒà¸Šà¹‰ cforest( ) à¸ˆà¸²à¸ package party
#                                                                                   à¹à¸—à¸™à¸à¹‡à¹„à¸”à¹‰à¹€à¸žà¸£à¸²à¸°à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸ˆ à¸²à¸à¸”à¸™à¸µ à¸± à¹‰)
# à¹ƒà¸™à¸—à¸µà¹ˆà¸™à¸µà¹‰à¸ˆà¸°à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ iris à¹ƒà¸™à¸à¸²à¸£à¸¨à¸¶à¸à¸©à¸²à¹à¸¥à¸°à¸—à¸”à¸ªà¸­à¸š
library(party)
library(randomForest)
rf <- randomForest(Survived ~ ., data = titanic_train, ntree = 100)
p <- predict(rf, newdata = titanic_test)
mean(p == titanic_test$Survived)
plot(p)
plot(rf)
plot(margin(rf, titanic_test$Survived))
pdf("script_pdf.pdf")
#Unit 3 Data Exploration
#dim() => ??????????????????????????? row,  cow,
#names() => ????????????????????? col
#str() => ?????????????????????????????? data frame
#attributs() => ???????????????????????? col , ?????????????????? (class) ????????? data ???????????? data.frame, ???????????? rows
dim(iris)
#row = 150, col = 5
names(iris)
#"Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width"  "Species"
str(iris)
attributes(iris)
graphics.off()
#lab 4 Linear Regression
year <- req(2008:2010, each)
#lab 4 Linear Regression
year <- rep(2008:2010, each)
#lab 4 Linear Regression
year <- rep(2008:2010, each = 4)
#lab 4 Linear Regression
year <- rep(2008:2010, each = 4)
View(year)
?rep
quarter <- rep(1:4, 3)
View(quarter)
cpi <- c(162.2, 164.6, 166.5, 166.0, 166.2, 167.0, 168.6, 169.5, 171.0, 172.1, 173.3. 174.0)
cpi <- c(162.2, 164.6, 166.5, 166.0, 166.2, 167.0, 168.6, 169.5, 171.0, 172.1, 173.3, 174.0)
plot(cpi, xaxt="n", ylab = "CPI", xlab = " ") #ylab, xlab = label
plot(cpi, year, ylab = "CPI", xlab = " ") #ylab, xlab = label
plot(year, cpi, ylab = "CPI", xlab = " ") #ylab, xlab = label
axis(1, labels = paste(year,quarter,sep = "Q"), at = 1:12, las = 3)
plot(cpi, xaxt="n", ylab = "CPI", xlab = " ") #ylab, xlab = label
axis(1, labels = paste(year,quarter,sep = "Q"), at = 1:12, las = 3)
#show correlation between CPI and other variable (year, quarter)
cor(year, cpi)
cor(quarter, cpi)
#Create regeression model
fit <- lm(cpi ~ year + quarter)
fit
#Predict
(cpi2011 <- fit$coefficients[[1]] + fit$coefficients[[2]]*2011 + fit$coefficients[[3]]*(1:4))
#Show detail lm
attributes(fit)
fit$coefficients
#show Error
residuals(fit)
summary(fit)
plot(fit)
#show plot 3d
library(scratterplot3d)
s3d <- scatterplot3d(year, quarter, cpi, hightlight.3d = T, type = "h", lab = c(2,3))
install.packages("scatterplot3d")
#show plot 3d
library(scatterplot3d)
s3d <- scatterplot3d(year, quarter, cpi, hightlight.3d = T, type = "h", lab = c(2,3))
s3d$plane3d(fit)
#User model to predic CPI 2011
data2011 <- data.frame(year=2011, quarter = 1:4)
cpi2011 <- predict(fit, newdata = data2011)
test <- rep(1,12)
#rep(1,12) gen number 1 for 12
style <- c(rep(1,12), rep(2,4))
View(style)
plot(c(cpi, cpi2011), xaxt="n", ylab = "CPI", xlab = " ", pch = style, col = style)
axis(1, at = 1:16, las = 3, labels = c(paste(year, quarter, sep = "Q")), "2011Q1", "2011Q2", "2011Q3", "2011Q4")
axis(1, at = 1:16, las = 3, labels = c(paste(year, quarter, sep = "Q"), "2011Q1", "2011Q2", "2011Q3", "2011Q4")
axis(1, at = 1:16, las = 3, labels = c(paste(year, quarter, sep = "Q"), "2011Q1", "2011Q2", "2011Q3", "2011Q4"))
axis(1, at = 1:16, las = 3, labels = c(paste(year, quarter, sep = "Q")), "2011Q1", "2011Q2", "2011Q3", "2011Q4")
axis(1, at = 1:16, las = 3, labels = c(paste(year, quarter, sep = "Q"), "2011Q1", "2011Q2", "2011Q3", "2011Q4"))
plot(c(cpi, cpi2011), xaxt="n", ylab = "CPI", xlab = " ", pch = style, col = style)
axis(1, at = 1:16, las = 3, labels = c(paste(year, quarter, sep = "Q"), "2011Q1", "2011Q2", "2011Q3", "2011Q4"))
plot(c(cpi, cpi2011), xaxt="n", ylab = "CPI", xlab = " ", pch = style, col = style)
axis(1, at = 1:16, las = 3, labels = c(paste(year, quarter, sep = "Q"), "2011Q1", "2011Q2", "2011Q3", "2011Q4"))
#Generalize Linear Regression (GLM)
data("bodyfat", package = "TH.data")
force(bodyfat)
myFormular <- DEXfat ~ age + waistcirc + hipcirc + elbowbreadth + kneebreadth
bodyfat.glm <- glm(myFormular, family = gaussian("log"), data = bodyfat)
summary(bodyfat.glm)
View(bodyfat.glm)
View(bodyfat.glm)
pred <- predict(bodyfat.glm, type = "response")
plot(bodyfat$DEXfat, pred, xlab = "Observed Values", ylab = "Predicted Values")
abline(a=0, b=1)
#Clustering Lab 4 Unit 6
#K-Means Clustering
iris2 <- iris
iris2$Species <- NULL
(kmeans.result <- kmeans(iris2, 3))
#à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² à¸ªà¸²à¸¡à¸²à¸£à¸–à¹à¸¢à¸ species à¹„à¸”à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸¡à¸²à¸à¸™à¹‰à¸­à¸¢à¹€à¸žà¸µà¸¢à¸‡à¹ƒà¸”
table(iris$Species, kmeans.result$cluster)
(kmeans.result <- kmeans(iris2, 3))
#à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² à¸ªà¸²à¸¡à¸²à¸£à¸–à¹à¸¢à¸ species à¹„à¸”à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸¡à¸²à¸à¸™à¹‰à¸­à¸¢à¹€à¸žà¸µà¸¢à¸‡à¹ƒà¸”
table(iris$Species, kmeans.result$cluster)
plot(iris2[c("Sepal.Length", "Sepal.Width")], col = kmeans.result$cluster)
#plot x center pointer of data set
points(kmeans.result$cluster[c("Sepal.Length", "Sepal.Width")], col = 1:3, pch = 8, cex = 2)
plot(iris2[c("Sepal.Length", "Sepal.Width")], col = kmeans.result$cluster)
#plot x center pointer of data set
points(kmeans.result$cluster[c("Sepal.Length", "Sepal.Width")], col = 1:3, pch = 8, cex = 2)
#plot x center pointer of data set
points(kmeans.result$cluster[, c("Sepal.Length", "Sepal.Width")], col = 1:3, pch = 8, cex = 2)
#plot x center pointer of data set
points(kmeans.result$cluster$centers[, c("Sepal.Length", "Sepal.Width")], col = 1:3, pch = 8, cex = 2)
#plot x center pointer of data set
points(kmeans.result$centers[, c("Sepal.Length", "Sepal.Width")], col = 1:3, pch = 8, cex = 2)
#K-Medoids Clustering
library(fpc)
install.packages("fpc")
#K-Medoids Clustering
library(fpc)
pamk.result <- pamk(iris2)
pamk.result$nc
table(pamk.result$pamobject$clustering, iris$Species)
layout(matrix(c(1,2), 1, 2))
plot(pamk.result$pamobject)
print(matrix(1))
layout(matrix(1))
pamk.result <- pam(iris2, 3)
pamk.result <- pamk(iris2, 3)
plot(pamk.result$pamobject)
table(pamk.result$pamobject$clustering, iris$Species) #check clustering againts actual species
layout(matrix(c(1,2), 1, 2)) #2 graphs per page
plot(pamk.result$pamobject)
layout(matrix(1)) #check back to one graph per page
pamk.result <- pamk(iris2, 3)
#Hierarchical Clustering
idx <- sample(1:dim(iris)[1], 40)
irisSample <- iris[idx,]
View(irisSample)
View(irisSample)
irisSample$Species <- NULL
hc <- hclust(dist(irisSample), method = "ave")
plot(hc, hang = -1, labels = "iris$Species[idx")
plot(hc, hang = -1, labels = iris$Species[idx])
#cut tree into 3 clusters
rect.hclust(hc, k = 3)
groups <- cutree(hc, k = 3)
#Density-base Clustering
library(fpc)
ds <- dbscan(iris2, eps = 0.42, MinPts = 5)
#compare clusters with original class lables
table(ds$cluster, iris$Species)
plot(ds, iris2)
plot(ds, iris2[c(1,4)])
print(iris)
print(iris[c(1,4)])
plotcluster(iris2, ds$cluster)
newData <- iris[idx, -5]
idx <- sample(1:nrow(iris), 10)
newData <- iris[idx, -5]
View(newData)
View(newData)
View(idx)
newData <- iris[idx]
newData <- iris[idx, -1]
newData2 <- iris[idx, -5]
View(newData2)
View(newData2)
newData <- iris[idx, -5] #-5 is not use column 5
newData <- newData + matrix(runif(10*4, min = 0, max = 0.2), nrow = 10, ncol = 4)
View(newData)
View(newData)
#label new data
myPred <- predict(ds, iris2, newData)
#plot result
plot(iris2[c(1,4)], col = 1 + ds$cluster)
points(newData[c(1,4)], pch = "ast", col = 1 + myPred, cex =3)
#check cluster lables
table(myPred, iris$Species[idx])
#Non-Linear Regression
#Non linear Regression à¸ˆà¸° plot à¹€à¸ªà¹‰à¸™à¸µà¹ˆà¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¹€à¸ªà¹‰à¸™à¸•à¸£à¸‡ à¹ƒà¸«à¹‰à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸¸à¸à¸•à¸±à¸§à¹ƒà¸«à¹‰à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”
set.seed(20160227)
x<-seq(0,50,1)
y<((runif(1,10,20)*x)/(runif(1,0,10)+x))+rnorm(51,0,1)
m<-nls(y~a*x/(b+x))
cor(y,predict(m))
#Create line between plot
abline(a=0, b=1)
#Create line between plot
abline(a=0, b=1)
plot(bodyfat$DEXfat, pred, xlab = "Observed Values", ylab = "Predicted Values")
#Create line between plot
abline(a=0, b=1)
#Non-Linear Regression
#Non linear Regression à¸ˆà¸° plot à¹€à¸ªà¹‰à¸™à¸µà¹ˆà¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¹€à¸ªà¹‰à¸™à¸•à¸£à¸‡ à¹ƒà¸«à¹‰à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸¸à¸à¸•à¸±à¸§à¹ƒà¸«à¹‰à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”
set.seed(20160227)
x<-seq(0,50,1)
y<((runif(1,10,20)*x)/(runif(1,0,10)+x))+rnorm(51,0,1)
y <- ((runif(1,10,20)*x)/(runif(1,0,10)+x))+rnorm(51,0,1)
m<-nls(y~a*x/(b+x))
#Create line between plot
abline(a=0, b=1)
plot(bodyfat$DEXfat, pred, xlab = "Observed Values", ylab = "Predicted Values")
#Generalize Linear Regression (GLM)
data("bodyfat", package = "TH.data")
myFormular <- DEXfat ~ age + waistcirc + hipcirc + elbowbreadth + kneebreadth
bodyfat.glm <- glm(myFormular, family = gaussian("log"), data = bodyfat)
summary(bodyfat.glm)
pred <- predict(bodyfat.glm, type = "response")
plot(bodyfat$DEXfat, pred, xlab = "Observed Values", ylab = "Predicted Values")
#Create line between plot
abline(a=0, b=1)
#Non-Linear Regression
#Non linear Regression à¸ˆà¸° plot à¹€à¸ªà¹‰à¸™à¸µà¹ˆà¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¹€à¸ªà¹‰à¸™à¸•à¸£à¸‡ à¹ƒà¸«à¹‰à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸¸à¸à¸•à¸±à¸§à¹ƒà¸«à¹‰à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”
set.seed(20160227)
x<-seq(0,50,1)
y <- ((runif(1,10,20)*x)/(runif(1,0,10)+x))+rnorm(51,0,1)
m<-nls(y~a*x/(b+x))
cor(y,predict(m))
plot(x,y)
lines(x,predict(m),lty=2,col="red",lwd=3)
year <- rep(2008:2010, each = 4)
quarter <- rep(1:4, 3)
cpi <- c(162.2, 164.6, 166.5, 166.0, 166.2, 167.0, 168.6, 169.5, 171.0, 172.1, 173.3, 174.0)
plot(cpi, xaxt="n", ylab = "CPI", xlab = " ") #ylab, xlab = label
axis(1, labels = paste(year,quarter,sep = "Q"), at = 1:12, las = 3)
#show correlation between CPI and other variable (year, quarter)
cor(year, cpi)
cor(quarter, cpi)
#Create regeression model
fit <- lm(cpi ~ year + quarter)
fit
#Predict
(cpi2011 <- fit$coefficients[[1]] + fit$coefficients[[2]]*2011 + fit$coefficients[[3]]*(1:4))
#Show detail lm
attributes(fit)
fit$coefficients
#show Error
residuals(fit)
summary(fit)
plot(fit)
s3d$plane3d(fit)
#User model to predic CPI 2011
data2011 <- data.frame(year=2011, quarter = 1:4)
cpi2011 <- predict(fit, newdata = data2011)
#rep(1,12) gen number 1 for 12
style <- c(rep(1,12), rep(2,4))
plot(c(cpi, cpi2011), xaxt="n", ylab = "CPI", xlab = " ", pch = style, col = style)
axis(1, at = 1:16, las = 3, labels = c(paste(year, quarter, sep = "Q"), "2011Q1", "2011Q2", "2011Q3", "2011Q4"))
#Generalize Linear Regression (GLM)
data("bodyfat", package = "TH.data")
myFormular <- DEXfat ~ age + waistcirc + hipcirc + elbowbreadth + kneebreadth
bodyfat.glm <- glm(myFormular, family = gaussian("log"), data = bodyfat)
summary(bodyfat.glm)
pred <- predict(bodyfat.glm, type = "response")
plot(bodyfat$DEXfat, pred, xlab = "Observed Values", ylab = "Predicted Values")
#Create line between plot
abline(a=0, b=1)
#Non-Linear Regression
#Non linear Regression à¸ˆà¸° plot à¹€à¸ªà¹‰à¸™à¸µà¹ˆà¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¹€à¸ªà¹‰à¸™à¸•à¸£à¸‡ à¹ƒà¸«à¹‰à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸¸à¸à¸•à¸±à¸§à¹ƒà¸«à¹‰à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”
set.seed(20160227)
x<-seq(0,50,1)
y <- ((runif(1,10,20)*x)/(runif(1,0,10)+x))+rnorm(51,0,1)
m<-nls(y~a*x/(b+x))
cor(y,predict(m))
plot(x,y)
lines(x,predict(m),lty=2,col="red",lwd=3)
install.packages("factoextra")
#Clustering Lab 4 Unit 6
#K-Means Clustering
iris2 <- iris
#delete col species out because we have to clustering species of iris
iris2$Species <- NULL
(kmeans.result <- kmeans(iris2, 3))
#Ã Â¸Â•Ã Â¸Â£Ã Â¸Â§Ã Â¸ÂˆÃ Â¸ÂªÃ Â¸­Ã Â¸ÂšÃ Â¸Â§Ã Â¹ÂˆÃ Â¸Â² Ã Â¸ÂªÃ Â¸Â²Ã Â¸Â¡Ã Â¸Â²Ã Â¸Â£Ã Â¸Â–Ã Â¹ÂÃ Â¸Â¢Ã Â¸Â species Ã Â¹Â„Ã Â¸Â”Ã Â¹Â‰Ã Â¸Â–Ã Â¸Â¹Ã Â¸ÂÃ Â¸Â•Ã Â¹Â‰Ã Â¸­Ã Â¸Â‡Ã Â¸Â¡Ã Â¸Â²Ã Â¸ÂÃ Â¸Â™Ã Â¹Â‰Ã Â¸­Ã Â¸Â¢Ã Â¹Â€Ã Â¸ÂžÃ Â¸ÂµÃ Â¸Â¢Ã Â¸Â‡Ã Â¹ÂƒÃ Â¸Â”
table(iris$Species, kmeans.result$cluster)
plot(iris2[c("Sepal.Length", "Sepal.Width")], col = kmeans.result$cluster)
#plot x center pointer of data set
points(kmeans.result$centers[, c("Sepal.Length", "Sepal.Width")], col = 1:3, pch = 8, cex = 2)
#K-Medoids Clustering
library(fpc)
pamk.result <- pamk(iris2)
pamk.result$nc #show number of clusters
table(pamk.result$pamobject$clustering, iris$Species) #check clustering againts actual species
layout(matrix(c(1,2), 1, 2)) #2 graphs per page
plot(pamk.result$pamobject)
layout(matrix(1)) #check back to one graph per page
#Hierarchical Clustering
idx <- sample(1:dim(iris)[1], 40)
irisSample <- iris[idx,]
irisSample$Species <- NULL
hc <- hclust(dist(irisSample), method = "ave")
plot(hc, hang = -1, labels = iris$Species[idx])
#Clustering Lab 4 Unit 6
#K-Means Clustering
iris2 <- iris
#K-Medoids Clustering
library(fpc)
pamk.result <- pamk(iris2)
pamk.result$nc #show number of clusters
table(pamk.result$pamobject$clustering, iris$Species) #check clustering againts actual species
#K-Medoids Clustering
library(fpc)
pamk.result <- pamk(iris2)
#delete col species out because we have to clustering species of iris
iris2$Species <- NULL
#K-Medoids Clustering
library(fpc)
pamk.result <- pamk(iris2)
pamk.result$nc #show number of clusters
table(pamk.result$pamobject$clustering, iris$Species) #check clustering againts actual species
layout(matrix(c(1,2), 1, 2)) #2 graphs per page
plot(pamk.result$pamobject)
layout(matrix(1)) #check back to one graph per page
plot(pamk.result$pamobject)
irisSample <- iris[idx,]
layout(matrix(1)) #check back to one graph per page
#Hierarchical Clustering
idx <- sample(1:dim(iris)[1], 40)
irisSample <- iris[idx,]
irisSample$Species <- NULL
hc <- hclust(dist(irisSample), method = "ave")
plot(hc, hang = -1, labels = iris$Species[idx])
#cut tree into 3 clusters
rect.hclust(hc, k = 3)
groups <- cutree(hc, k = 3)
#Density-base Clustering
library(fpc)
iris2 <- iris[-5] #remove classs tags
ds <- dbscan(iris2, eps = 0.42, MinPts = 5)
#compare clusters with original class lables
table(ds$cluster, iris$Species)
plot(ds, iris2)
#plot iris2 col 1 and 4
plot(ds, iris2[c(1,4)])
plotcluster(iris2, ds$cluster)
#Create a new dataset for labeling
set.seed(435)
idx <- sample(1:nrow(iris), 10)
newData <- iris[idx, -5] #-5 is not use column 5
#plus matrix random data
newData <- newData + matrix(runif(10*4, min = 0, max = 0.2), nrow = 10, ncol = 4)
#label new data
myPred <- predict(ds, iris2, newData)
#plot result
plot(iris2[c(1,4)], col = 1 + ds$cluster)
points(newData[c(1,4)], pch = "ast", col = 1 + myPred, cex =3)
#check cluster lables
table(myPred, iris$Species[idx])
#Clustering Lab 4 Unit 6
#K-Means Clustering
iris2 <- iris #à¸ªà¸£à¹‰à¸²à¸‡à¸•à¸±à¸§à¹à¸›à¸£ iris2 à¸ˆà¸²à¸ iris (à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š)
#delete col species out because we have to clustering species of iris
iris2$Species <- NULL #à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™ col species à¹€à¸žà¸·à¹ˆà¸­à¸ˆà¸°à¹ƒà¸Šà¹‰à¸—à¸”à¸¥à¸­à¸‡à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡
(kmeans.result <- kmeans(iris2, 3)) #à¸—à¸³à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ kmeans (à¸Šà¸¸à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥, à¸ˆà¸³à¸™à¸§à¸™ K à¸à¸¥à¸¸à¹ˆà¸¡)
##à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² à¸ªà¸²à¸¡à¸²à¸£à¸–à¹à¸¢à¸ species à¹„à¸”à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸¡à¸²à¸à¸™à¹‰à¸­à¸¢à¹€à¸žà¸µà¸¢à¸‡à¹ƒà¸”
table(iris$Species, kmeans.result$cluster)
plot(iris2[c("Sepal.Length", "Sepal.Width")], col = kmeans.result$cluster)
pamk.result <- pamk(iris2) #à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ algorithms pamk
pamk.result$nc #show number of clusters
table(pamk.result$pamobject$clustering, iris$Species) #check clustering againts actual species
layout(matrix(c(1,2), 1, 2)) #2 graphs per page
plot(pamk.result$pamobject) #plot à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¸”à¹‰à¸§à¸¢ pamk
#Hierarchical Clustering
idx <- sample(1:dim(iris)[1], 40)
View(idx)
dim(iris)
